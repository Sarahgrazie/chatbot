import streamlit as st
import os
from openai import OpenAI

# ---------------------
# ğŸ¯ ì¥ì†Œë³„ ì´ë¯¸ì§€ & ì„¤ëª… ì‚¬ì „
# ---------------------
place_images = {
    "ì˜¤í˜ë¼ í•˜ìš°ìŠ¤": {
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/40/Sydney_Opera_House_Sails.jpg",
        "desc": "ì‹œë“œë‹ˆì˜ ëœë“œë§ˆí¬! ë…íŠ¹í•œ ì§€ë¶• ë””ìì¸ìœ¼ë¡œ ì„¸ê³„ì ìœ¼ë¡œ ìœ ëª…í•œ ê³µì—° ì˜ˆìˆ  ê³µê°„ì´ì—ìš”."
    },
    "í•˜ë²„ ë¸Œë¦¬ì§€": {
        "image": "https://upload.wikimedia.org/wikipedia/commons/b/bb/Sydney_Harbour_Bridge_night.jpg",
        "desc": "ì‹œë“œë‹ˆ í•­êµ¬ë¥¼ ì‡ëŠ” ê±°ëŒ€í•œ ì² ì œ ì•„ì¹˜í˜• ë‹¤ë¦¬. ë„ë³´ë¡œ ê±´ë„ ìˆ˜ë„ ìˆì–´ìš”!"
    },
    "ë³¸ë‹¤ì´ ë¹„ì¹˜": {
        "image": "https://upload.wikimedia.org/wikipedia/commons/5/5a/Bondi_Beach_aerial.jpg",
        "desc": "ì„œí•‘, ì‚°ì±…, ì—¬ìœ ë¡œìš´ í•˜ë£¨ ë³´ë‚´ê¸°ì— ì™„ë²½í•œ ì•„ë¦„ë‹¤ìš´ í•´ë³€ì´ì—ìš”."
    },
    "íƒ€ë¡±ê°€ ë™ë¬¼ì›": {
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/41/Taronga_Zoo_skyline.jpg",
        "desc": "ì½”ì•Œë¼, ìº¥ê±°ë£¨ë¥¼ ì§ì ‘ ë³¼ ìˆ˜ ìˆëŠ” ì‹œë“œë‹ˆ ìµœê³ ì˜ ë™ë¬¼ì›!"
    },
    "ë¸”ë£¨ë§ˆìš´í‹´": {
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/47/Three_Sisters_BM_NSW_Australia.jpg",
        "desc": "ì¥ì—„í•œ ìì—° ì ˆê²½ê³¼ 'ì„¸ ìë§¤ ë°”ìœ„'ë¡œ ìœ ëª…í•œ êµ­ë¦½ê³µì›. ë‹¹ì¼ì¹˜ê¸° ì—¬í–‰ìœ¼ë¡œ ì¸ê¸°!"
    }
}

# ---------------------
# ğŸï¸ ë¬¸ë„ë¦¬ ìŠ¤íƒ€ì¼ ì†Œê°œ
# ---------------------
st.markdown("""
### ğŸ¨ğŸ¦˜ ê·€ì—¬ìš´ ë¬¸ë„ë¦¬ì™€ í•¨ê»˜í•˜ëŠ” í˜¸ì£¼ ì‹œë“œë‹ˆ ì—¬í–‰ ğŸ¦˜ğŸ¨  

GPT-3.5ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—¬í–‰ì§€ì—ì„œ ë³´ë‹¤ ì¦ê²ê³  í’ì„±í•œ ì‹œê°„ì„ ë³´ë‚´ì‹¤ ìˆ˜ ìˆë„ë¡ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤. 

ì§€ê¸ˆ ë°”ë¡œ ì‹œë“œë‹ˆ ì—¬í–‰ì„ ì‹œì‘í•´ë³¼ê¹Œìš”? ğŸŒâœˆï¸
""")

# ---------------------
# ğŸ”‘ API í‚¤ ì…ë ¥
# ---------------------
openai_api_key = st.text_input("ğŸ” OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
if not openai_api_key:
    st.info("API í‚¤ë¥¼ ì…ë ¥í•˜ì‹œë©´ ì±—ë´‡ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”!", icon="ğŸ”‘")
    st.stop()
else:
    os.environ["OPENAI_API_KEY"] = openai_api_key
    client = OpenAI()

# ---------------------
# âœˆï¸ ì—¬í–‰ ì •ë³´ ì…ë ¥
# ---------------------
travel_days = st.slider("â³ ì—¬í–‰ì€ ë©°ì¹  ì˜ˆì •ì¸ê°€ìš”?", 1, 14, 4)

with st.expander("ğŸ’ ì—¬í–‰ ìŠ¤íƒ€ì¼ ì„ íƒ"):
    travel_styles = st.multiselect(
        "ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥!",
        ["ë§›ì§‘ íƒë°©", "ìì—° íë§", "ë¬¸í™” ì²´í—˜", "ì‚¬ì§„ ì°ê¸°", "ì‡¼í•‘", "í˜¼ì ì—¬í–‰", "ê°€ì¡± ì—¬í–‰", "ì»¤í”Œ ì—¬í–‰"]
    )

# ---------------------
# ğŸ’¬ ì´ì „ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ---------------------
# ğŸ—ºï¸ GPTë¡œ ì—¬í–‰ ì¼ì • ì¶”ì²œ
# ---------------------
if st.button("ğŸ—ºï¸ ë‚˜ë§Œì˜ ì—¬í–‰ ì¼ì • ì¶”ì²œë°›ê¸°"):
    if not travel_styles:
        st.warning("ì—¬í–‰ ìŠ¤íƒ€ì¼ì„ ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”!")
    else:
        user_prompt = f"""
        ì €ëŠ” {travel_days}ì¼ ë™ì•ˆ ì‹œë“œë‹ˆ ì—¬í–‰ì„ í•  ì˜ˆì •ì…ë‹ˆë‹¤.
        ì—¬í–‰ ìŠ¤íƒ€ì¼ì€ {', '.join(travel_styles)} ì…ë‹ˆë‹¤.
        ì´ ìŠ¤íƒ€ì¼ì— ë§ëŠ” ì—¬í–‰ ì¼ì •ê³¼ ì¶”ì²œ ì¥ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
        """

        st.session_state.messages.append({"role": "user", "content": user_prompt})
        with st.chat_message("user"):
            st.markdown(user_prompt)

        try:
            stream = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ],
                stream=True,
            )

            with st.chat_message("assistant"):
                response = st.write_stream(stream)

            st.session_state.messages.append({"role": "assistant", "content": response})

            # ğŸ” GPT ì‘ë‹µ ì¤‘ ì¥ì†Œ ì´ë¦„ í¬í•¨ëœ ê²ƒ ì°¾ê¸°
            for place, data in place_images.items():
                if place in response:
                    st.image(data["image"], caption=place, use_container_width=True)
                    st.markdown(f"ğŸ“ {data['desc']}")

        except Exception as e:
            st.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆì–´ìš”: {e}")

# ---------------------
# ğŸ’¬ ììœ  ì§ˆë¬¸ ì…ë ¥
# ---------------------
if prompt := st.chat_input("ì‹œë“œë‹ˆ ì—¬í–‰ì´ ê¶ê¸ˆí•œê°€ìš”? ììœ ë¡­ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        stream = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],
            stream=True,
        )

        with st.chat_message("assistant"):
            response = st.write_stream(stream)

        st.session_state.messages.append({"role": "assistant", "content": response})

        for place, data in place_images.items():
            if place in response:
                st.image(data["image"], caption=place, use_column_width=True)
                st.markdown(f"ğŸ“ {data['desc']}")

    except Exception as e:
        st.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆì–´ìš”: {e}")
